{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.similarity_search.metric import *\n",
    "from src.similarity_search.similarity_search_image import *\n",
    "from src.similarity_search.similarity_search_text import *\n",
    "from src.similarity_search.mixed_model import *\n",
    "from src.similarity_search.utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate tf-idf, Siamese CNN and multi-modal baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requisites: generate_training_data.ipynb was run and traning datasets were generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"TrainingData/SingleCategory/\"\n",
    "image_path = \"Images/\"\n",
    "model_path = \"Model/TrainedModel/\"\n",
    "ditto_input_path = \"TrainingData/AllCategories/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['art', 'pet', 'home', 'garden', 'sport', 'toy', 'tool']\n",
    "res = {}\n",
    "for cat in cats:\n",
    "    print(\"category: \", cat)\n",
    "    res[cat]={}\n",
    "    X_ID_left_train, X_ID_right_train, X_text_left_train, X_text_right_train, Y_train =\\\n",
    "                                                                    get_data(input_path+f\"{cat}_train.jsonl\")\n",
    "    X_ID_left_test, X_ID_right_test, X_text_left_test, X_text_right_test, Y_test =\\\n",
    "                                                                    get_data(input_path+f\"{cat}_test.jsonl\")\n",
    "    Y_train = np.asarray(Y_train)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "    res[cat][\"X_ID_left_train\"]=X_ID_left_train\n",
    "    res[cat][\"X_ID_right_train\"]=X_ID_right_train\n",
    "    res[cat][\"X_ID_left_test\"]=X_ID_left_test\n",
    "    res[cat][\"X_ID_right_test\"]=X_ID_right_test\n",
    "    res[cat][\"Y_train\"]=Y_train\n",
    "    res[cat][\"Y_test\"]=Y_test\n",
    "    # Fit Text\n",
    "    similarity_search_text_model = TextClassifier()    \n",
    "    Precision, Recall, interpolated_precision,\\\n",
    "         F1, optimal_threshold_text, scores_text = similarity_search_text_model.train(\\\n",
    "                                                    X_text_left_train, X_text_right_train, Y_train)\n",
    "    res[cat][\"Precision_text_train\"]=Precision\n",
    "    res[cat][\"Recall_text_train\"]=Recall\n",
    "    res[cat][\"interpolated_precision_text_train\"]=interpolated_precision\n",
    "    res[cat][\"F1_text_train\"]=F1\n",
    "    res[cat][\"optimal_threshold_text\"]=optimal_threshold_text\n",
    "    res[cat][\"scores_text_train\"]=scores_text\n",
    "    print(f\"Optimal threshold for image similarity search: {optimal_threshold_text}\")\n",
    "    print(f\"Maximal F1 of text similarity search: {np.max(F1)}\")\n",
    "\n",
    "    # Test\n",
    "    metrics, scores_text_test = similarity_search_text_model.test(\\\n",
    "                                X_text_left_test, X_text_right_test,\\\n",
    "                                Y_test, optimal_threshold_text, return_score=True)\n",
    "    F1_test, Precision_test, Recall_test, Accuracy_test = metrics\n",
    "    res[cat][\"F1_text_test\"]=F1_test\n",
    "    res[cat][\"Precision_text_test\"]=Precision_test\n",
    "    res[cat][\"Recall_text_test\"]=Recall_test\n",
    "    res[cat][\"Accuracy_test\"]=Accuracy_test\n",
    "    res[cat][\"scores_text_test\"]=scores_text_test\n",
    "    print(\"Evaluate text model on test data\")\n",
    "    print(f\" F1 = {F1_test}\\n Precision = {Precision_test}\\n Recall = {Recall_test}\\n Accuracy = {Accuracy_test}\")\n",
    "    \n",
    "    # load image data\n",
    "    X_train_image_left = load_image_per_ID(X_ID_left_train, image_path, target_size = (32, 32))\n",
    "    X_train_image_right = load_image_per_ID(X_ID_right_train, image_path, target_size = (32, 32))\n",
    "    X_test_image_left = load_image_per_ID(X_ID_left_test, image_path, target_size = (32, 32))\n",
    "    X_test_image_right = load_image_per_ID(X_ID_right_test, image_path, target_size = (32, 32))\n",
    "    # Resize images\n",
    "    X_train_image_left = X_train_image_left.reshape((len(X_train_image_left), 1, 32, 32, 3))\n",
    "    X_train_image_right = X_train_image_right.reshape((len(X_train_image_right), 1, 32, 32, 3))\n",
    "    X_test_image_left = X_test_image_left.reshape((len(X_test_image_left), 1, 32, 32, 3))\n",
    "    X_test_image_right = X_test_image_right.reshape((len(X_test_image_right), 1, 32, 32, 3))\n",
    "    \n",
    "    # Load embedding model\n",
    "    img_model = ImageClassifier(f\"{model_path}embedding_{cat}\", load=True) \n",
    "    # Fit\n",
    "    Precision, Recall, interpolated_precision,\\\n",
    "    F1, optimal_threshold_img, scores_img = img_model.train(X_train_image_left, X_train_image_right, Y_train)\n",
    "    print(f\"Optimal threshold for image similarity search: {optimal_threshold_img}\")\n",
    "    print(f\"Maximal F1 of text similarity search: {np.max(F1)}\")\n",
    "    res[cat][\"Precision_img_train\"]=Precision\n",
    "    res[cat][\"Recall_img_train\"]=Recall\n",
    "    res[cat][\"interpolated_precision_img_train\"]=interpolated_precision\n",
    "    res[cat][\"F1_img_train\"]=F1\n",
    "    res[cat][\"optimal_threshold_img\"]=optimal_threshold_img\n",
    "    res[cat][\"scores_img_train\"]=scores_img\n",
    "    # Test\n",
    "    metrics, scores_img_test = img_model.test(X_test_image_left,\\\n",
    "                                    X_test_image_right,\\\n",
    "                                    Y_test, optimal_threshold_img, return_score=True)\n",
    "    F1_test, Precision_test, Recall_test, Accuracy_test = metrics\n",
    "    res[cat][\"F1_img_test\"]=F1_test\n",
    "    res[cat][\"Precision_img_test\"]=Precision_test\n",
    "    res[cat][\"Recall_img_test\"]=Recall_test\n",
    "    res[cat][\"Accuracy_test\"]=Accuracy_test\n",
    "    res[cat][\"scores_img_test\"]=scores_img_test\n",
    "    print(\"Evaluate image model on test data\")\n",
    "    print(f\" F1 = {F1_test}\\n Precision = {Precision_test}\\n Recall = {Recall_test}\\n Accuracy = {Accuracy_test}\")   \n",
    "    \n",
    "    # Test both\n",
    "    mixed_model = MixClassifier(text_model=similarity_search_text_model, image_model=img_model)\n",
    "    max_f1, coef_text, coef_image, opt_theta, scores = find_optimal_coef(scores_text, scores_img, Y_train)\n",
    "    res[cat][\"max_f1_mixed\"]=max_f1\n",
    "    res[cat][\"coef_text\"]=coef_text\n",
    "    res[cat][\"coef_image\"]=coef_image\n",
    "    res[cat][\"opt_theta\"]=opt_theta\n",
    "    res[cat][\"scores_train\"]=scores\n",
    "    print(\"Optimal values:\")\n",
    "    print(f\"Maximal F1 = {max_f1}\")\n",
    "    print(f\"Coefficient text = {coef_text}\")\n",
    "    print(f\"Coefficient image = {coef_image}\")\n",
    "    print(f\"Threshold = {opt_theta}\")\n",
    "    F1, Precision, Recall, Accuracy, score_text, score_image, scores_test =  mixed_model.test_combine_model(\\\n",
    "                            X_text_left_test, X_text_right_test, \\\n",
    "                            X_test_image_left,\\\n",
    "                            X_test_image_right,\\\n",
    "                            coef_text, coef_image, opt_theta, Y_test, return_score=True)\n",
    "    res[cat][\"F1_mixed\"]=F1\n",
    "    res[cat][\"Precision_mixed\"]=Precision\n",
    "    res[cat][\"Recall_mixed\"]=Recall\n",
    "    res[cat][\"Accuracy_mixed\"]=Accuracy\n",
    "    res[cat][\"scores_test_mixed\"]=scores_test\n",
    "    print(\"Evaluate mixed model on test data\")\n",
    "    print(f\" F1 = {F1}\\n Precision = {Precision}\\n Recall = {Recall}\\n Accuracy = {Accuracy}\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"category\"]+list(res[\"art\"].keys()))\n",
    "for k,v in res.items():    \n",
    "    df.loc[len(df)] = [k]+list(v.values())\n",
    "df.to_pickle(\"Result/tfidf_cnn_multimodalbaseline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate Ditto per category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requisites: Ditto model was trained and tested on the generated test dataset. The output was then saved into Result folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_ditto_output(input_filename, output_filename):\n",
    "    preds=[]\n",
    "    scores=[]\n",
    "    labels=[]\n",
    "    with jsonlines.open(output_filename) as fh:\n",
    "        for line in fh:\n",
    "            pred = int(line[\"match\"])\n",
    "            preds.append(pred)\n",
    "            if pred==1:\n",
    "                scores.append(line[\"match_confidence\"])\n",
    "            else:\n",
    "                scores.append(1-line[\"match_confidence\"])\n",
    "    mapper = {}\n",
    "    with jsonlines.open(input_filename) as fh:\n",
    "        for i, line in enumerate(fh):\n",
    "            ID1 = re.search(f'https://www.amazon.com/dp/(.+)', line['ID1']).group(1)\n",
    "            ID2 = re.search(f'https://www.amazon.com/dp/(.+)', line['ID2']).group(1)\n",
    "            mapper[(ID1, ID2)] = [line[\"label\"], scores[i], preds[i]]\n",
    "            labels.append(line[\"label\"])\n",
    "    return mapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapper_test = map_ditto_output(f\"{ditto_input_path}test.jsonl\", \"Result/ditto_output_test.jsonl\")\n",
    "mapper_train = map_ditto_output(f\"{ditto_input_path}train.jsonl\", \"Result/ditto_output_train.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['art', 'pet', 'home', 'garden', 'sport', 'toy', 'tool']\n",
    "res = {}\n",
    "\n",
    "for cat in cats:\n",
    "    res[cat]={}\n",
    "    X_ID_left_train, X_ID_right_train, X_text_left_train, X_text_right_train, Y_train = get_data(input_path+f\"{cat}_train.jsonl\")\n",
    "    X_ID_left_test, X_ID_right_test, X_text_left_test, X_text_right_test, Y_test = get_data(input_path+f\"{cat}_test.jsonl\")\n",
    "    Y_train = np.asarray(Y_train)\n",
    "    Y_test = np.asarray(Y_test)\n",
    "    ditto_scores_train=[]; ditto_preds_train=[]\n",
    "    ditto_scores_test=[]; ditto_preds_test=[]\n",
    "    for i in range(len(X_ID_left_test)):\n",
    "        (ID1, ID2) = X_ID_left_test[i], X_ID_right_test[i]\n",
    "        ditto_preds_test.append(mapper_test[(ID1, ID2)][2])        \n",
    "        ditto_scores_test.append(mapper_test[(ID1, ID2)][1])\n",
    "    for i in range(len(X_ID_left_train)):\n",
    "        (ID1, ID2) = X_ID_left_train[i], X_ID_right_train[i]\n",
    "        ditto_preds_train.append(mapper_train[(ID1, ID2)][2])        \n",
    "        ditto_scores_train.append(mapper_train[(ID1, ID2)][1])\n",
    "    res[cat][\"ditto_scores_train\"] = ditto_scores_train\n",
    "    res[cat][\"ditto_preds_train\"] = ditto_preds_train\n",
    "    res[cat][\"Y_train\"] = Y_train\n",
    "    res[cat][\"ditto_scores_test\"] = ditto_scores_test\n",
    "    res[cat][\"ditto_preds_test\"] = ditto_preds_test\n",
    "    res[cat][\"Y_test\"] = Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=['Category', \"ditto_scores_train\", \"ditto_preds_train\", \"Y_train\",\\\n",
    "                           \"ditto_scores_test\",\"ditto_preds_test\", \"Y_test\"])\n",
    "for cat in cats:\n",
    "    df.loc[len(df)] = [cat, res[cat][\"ditto_scores_train\"], res[cat][\"ditto_preds_train\"], res[cat][\"Y_train\"],\\\n",
    "                      res[cat][\"ditto_scores_test\"], res[cat][\"ditto_preds_test\"], res[cat][\"Y_test\"]]\n",
    "df.to_pickle(\"ditto_result_per_cat.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate multi-modal model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# result of image model\n",
    "df_img = pd.read_pickle(\"Result/tfidf_cnn_multimodalbaseline.pkl\")\n",
    "# result of ditto model\n",
    "df_ditto = pd.read_pickle(\"Result/ditto_result_per_cat.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_simple(labels, preds):\n",
    "    F1 = f1_score(labels, preds)\n",
    "    Precision = precision_score(labels, preds)\n",
    "    Recall = recall_score(labels, preds)\n",
    "    Accuracy = accuracy_score(labels, preds)\n",
    "    return F1, Precision, Recall, Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = ['art', 'pet', 'home', 'garden', 'sport', 'toy', 'tool']\n",
    "res={}\n",
    "for i,cat in enumerate(cats):\n",
    "    print(\"category: \", cat)\n",
    "    res[cat]={}\n",
    "    scores_ditto, scores_img = np.asarray(df_ditto.loc[i][\"ditto_scores_test\"]), df_img.loc[i][\"scores_img_test\"]\n",
    "    Y_test = df_ditto.loc[i][\"Y_test\"]\n",
    "    max_f1, coef_text, coef_image, opt_theta, scores = find_optimal_coef(scores_ditto, scores_img, Y_test)\n",
    "    res[cat][\"max_f1_mixed\"]=max_f1\n",
    "    res[cat][\"coef_text\"]=coef_text\n",
    "    res[cat][\"coef_image\"]=coef_image\n",
    "    res[cat][\"opt_theta\"]=opt_theta\n",
    "    res[cat][\"scores_ditto\"]=scores_ditto\n",
    "    res[cat][\"scores_img\"]=scores_img\n",
    "    res[cat][\"scores_mixed\"]=scores\n",
    "    res[cat][\"Y_test\"]=Y_test\n",
    "    scores_test = scores_ditto*coef_text + scores_img*coef_image\n",
    "    F1, Precision, Recall, Accuracy = evaluate(Y_test, scores_test, opt_theta)\n",
    "    \n",
    "    F1_ditto_test, Precision_ditto_test, Recall_ditto_test, Accuracy_ditto_test = eval_simple(Y_test, df_ditto.loc[i][\"ditto_preds_test\"])\n",
    "    F1_text_test,F1_img_test, F1_mixed_text_img_test = df_img.loc[i]['F1_text_test'],\\\n",
    "                                                    df_img.loc[i]['F1_img_test'],df_img.loc[i]['F1_mixed']\n",
    "    res[cat][\"F1_mixed_ditto_img_test\"]=F1\n",
    "    res[cat][\"Precision_mixed_ditto_img_test\"]=Precision\n",
    "    res[cat][\"Recall_mixed_ditto_img_test\"]=Recall\n",
    "    res[cat][\"Accuracy_mixed_ditto_img_test\"]=Accuracy\n",
    "    res[cat][\"scores_test_mixed_ditto_img_test\"]=scores_test\n",
    "    \n",
    "    res[cat][\"F1_ditto_test\"]=F1_ditto_test\n",
    "    res[cat][\"Precision_ditto_test\"]=Precision_ditto_test\n",
    "    res[cat][\"Recall_ditto_test\"]=Recall_ditto_test\n",
    "    res[cat][\"Accuracy_ditto_test\"]=Accuracy_ditto_test\n",
    "    \n",
    "    res[cat][\"F1_text_test\"]=F1_text_test\n",
    "    res[cat][\"F1_img_test\"]=F1_img_test\n",
    "    res[cat][\"F1_mixed_text_img_test\"]=F1_mixed_text_img_test\n",
    "    print(\"Optimal values:\")\n",
    "    print(f\"Maximal F1 = {max_f1}\")\n",
    "    print(f\"Coefficient text = {coef_text}\")\n",
    "    print(f\"Coefficient image = {coef_image}\")\n",
    "    print(f\"Threshold = {opt_theta}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(columns=[\"category\"]+list(res[\"art\"].keys()))\n",
    "for k,v in res.items():    \n",
    "    df.loc[len(df)] = [k]+list(v.values())\n",
    "df.to_pickle(\"Result/ditto_cnn_multimodalbaseline.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results of all models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1 left"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>tf-idf</th>\n",
       "      <th>Siamese CNN</th>\n",
       "      <th>Ditto</th>\n",
       "      <th>Multi-modal baseline</th>\n",
       "      <th>Multi-modal model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>0.880325</td>\n",
       "      <td>0.885375</td>\n",
       "      <td>0.947791</td>\n",
       "      <td>0.965235</td>\n",
       "      <td>0.979839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet</td>\n",
       "      <td>0.640693</td>\n",
       "      <td>0.582781</td>\n",
       "      <td>0.743875</td>\n",
       "      <td>0.680244</td>\n",
       "      <td>0.754717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home</td>\n",
       "      <td>0.656904</td>\n",
       "      <td>0.588921</td>\n",
       "      <td>0.840764</td>\n",
       "      <td>0.691511</td>\n",
       "      <td>0.864035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garden</td>\n",
       "      <td>0.707566</td>\n",
       "      <td>0.585714</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.742972</td>\n",
       "      <td>0.825462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sport</td>\n",
       "      <td>0.794926</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.836292</td>\n",
       "      <td>0.829569</td>\n",
       "      <td>0.873418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toy</td>\n",
       "      <td>0.654397</td>\n",
       "      <td>0.572230</td>\n",
       "      <td>0.808853</td>\n",
       "      <td>0.697769</td>\n",
       "      <td>0.822511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tool</td>\n",
       "      <td>0.653061</td>\n",
       "      <td>0.535613</td>\n",
       "      <td>0.831224</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.840708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category    tf-idf  Siamese CNN     Ditto  Multi-modal baseline  \\\n",
       "0      art  0.880325     0.885375  0.947791              0.965235   \n",
       "1      pet  0.640693     0.582781  0.743875              0.680244   \n",
       "2     home  0.656904     0.588921  0.840764              0.691511   \n",
       "3   garden  0.707566     0.585714  0.829365              0.742972   \n",
       "4    sport  0.794926     0.636364  0.836292              0.829569   \n",
       "5      toy  0.654397     0.572230  0.808853              0.697769   \n",
       "6     tool  0.653061     0.535613  0.831224              0.644000   \n",
       "\n",
       "   Multi-modal model  \n",
       "0           0.979839  \n",
       "1           0.754717  \n",
       "2           0.864035  \n",
       "3           0.825462  \n",
       "4           0.873418  \n",
       "5           0.822511  \n",
       "6           0.840708  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"Result/result_all_models.pkl\")\n",
    "df = df.rename(columns={\"F1_text_test\": \"tf-idf\", \"F1_img_test\": \"Siamese CNN\", \"F1_ditto_test\": \"Ditto\", \n",
    "                   \"F1_mixed_text_img_test\": \"Multi-modal baseline\", \"F1_mixed_ditto_img_test\": \"Multi-modal model\"})\n",
    "df[['category','tf-idf', 'Siamese CNN', 'Ditto', 'Multi-modal baseline', 'Multi-modal model']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table 1 right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>β</th>\n",
       "      <th>1-β</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>art</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pet</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>home</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>garden</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sport</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toy</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tool</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category     β   1-β\n",
       "0      art  0.47  0.53\n",
       "1      pet  0.84  0.16\n",
       "2     home  0.66  0.34\n",
       "3   garden  0.72  0.28\n",
       "4    sport  0.65  0.35\n",
       "5      toy  0.67  0.33\n",
       "6     tool  0.63  0.37"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"Result/result_all_models.pkl\")\n",
    "df = df.rename(columns={\"coef_text\": \"β\", \"coef_image\": \"1-β\"})\n",
    "df[[\"category\", \"β\", \"1-β\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ac3a4f718b317d0f59de664fd35a817365df8aa5069a306a5d5a85d818aebd22"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
